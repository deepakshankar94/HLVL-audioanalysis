{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roxor/bin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing your install of VGGish\n",
      "\n",
      "Log Mel Spectrogram example:  [[-4.47297436 -4.29457354 -4.14940631 ... -3.9747003  -3.94774997\n",
      "  -3.78687669]\n",
      " [-4.48589533 -4.28825497 -4.139964   ... -3.98368686 -3.94976505\n",
      "  -3.7951698 ]\n",
      " [-4.46158065 -4.29329706 -4.14905953 ... -3.96442484 -3.94895483\n",
      "  -3.78619839]\n",
      " ...\n",
      " [-4.46152626 -4.29365061 -4.14848608 ... -3.96638113 -3.95057575\n",
      "  -3.78538167]\n",
      " [-4.46152595 -4.2936572  -4.14848104 ... -3.96640507 -3.95059567\n",
      "  -3.78537143]\n",
      " [-4.46152565 -4.29366386 -4.14847603 ... -3.96642906 -3.95061564\n",
      "  -3.78536116]]\n",
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
      "VGGish embedding:  [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16137297 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.80695784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.36792752 0.03582409 0.         0.         0.\n",
      " 0.         0.38027024 0.13755932 0.9174709  0.80656326 0.\n",
      " 0.         0.         0.         0.04036275 0.7076243  0.\n",
      " 0.497839   0.24081805 0.21565434 0.88492286 1.1956799  0.6706197\n",
      " 0.20779464 0.01639864 0.17471862 0.         0.         0.25100806\n",
      " 0.         0.         0.14607912 0.         0.39887047 0.30542114\n",
      " 0.12896752 0.         0.         0.         0.         0.\n",
      " 0.53851336 0.         0.         0.04941075 0.425274   0.18537286\n",
      " 0.         0.         0.14753519 0.         0.         0.6993387\n",
      " 0.4554119  0.05174816 0.         0.01992545 0.         0.\n",
      " 0.5181578  0.56557596 0.65879744 0.         0.         0.41056335\n",
      " 0.         0.         0.         0.25765198 0.23232114 0.24026456\n",
      " 0.         0.         0.         0.         0.         0.26523757\n",
      " 0.         0.48460817 0.         0.         0.19325784 0.\n",
      " 0.20123348 0.         0.03368615 0.         0.         0.\n",
      " 0.         0.17836356 0.02474903 0.0688998  0.         0.\n",
      " 0.         0.08246282 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Postprocessed VGGish embedding:  [169  10 154 127 191  66 124  69 157 232 142  21 128 131  43   3  33 111\n",
      " 198 153  76 255 194  60  71 179 146 131 167  60  79  76 192  84 102 160\n",
      "  23  91 173  13 149 186 115 202 252 163  84 145 107 255   5 198  81   0\n",
      " 203 110  35 104 101 131 255   0   0 158 136  74 115 152  77 154  54 151\n",
      "  82 243  57 116 165 153  85 181 152   0 255 122  29 255  46 105 110  43\n",
      "   0  90  58  13 255 108  96 255  84 121 255  75 176 111 176  64  83 231\n",
      " 255  82 255  94  81 144  99 173 255   0   0 158  31 230 112 255   0 255\n",
      "  20 255]\n",
      "\n",
      "Looks Good To Me!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vggish_smoke_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = wavfile.read(\"test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, array([[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=int16))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = wavfile.read(\"mine.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44100, array([[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=int16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = a[1] / 32768.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00076294, -0.00076294])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[21334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_params.SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_params.STFT_HOP_LENGTH_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sample_rate = 1.0 / vggish_params.STFT_HOP_LENGTH_SECONDS\n",
    "example_window_length = int(round(\n",
    "      vggish_params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))\n",
    "example_hop_length = int(round(\n",
    "      vggish_params.EXAMPLE_HOP_SECONDS * features_sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_window_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vggish_input.wavfile_to_examples(\"test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Test these new functions with the original test.\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "vgg = CreateVGGishNetwork(0.01)\n",
    "\n",
    "# Generate a 1 kHz sine wave at 44.1 kHz (we use a high sampling rate\n",
    "# to test resampling to 16 kHz during feature extraction).\n",
    "num_secs = 3\n",
    "freq = 1000\n",
    "sr = 44100\n",
    "t = np.linspace(0, num_secs, int(num_secs * sr))\n",
    "x = np.sin(2 * np.pi * freq * t)  # Unit amplitude input signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132300,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = vggish_input.wavfile_to_examples(\"2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 96, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = vggish_input.wavfile_to_examples(\"test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 96, 64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roxor/bin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import vggish_slim\n",
    "import vggish_params\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "\n",
    "def CreateVGGishNetwork(hop_size=0.96):   # Hop size is in seconds.\n",
    "  \"\"\"Define VGGish model, load the checkpoint, and return a dictionary that points\n",
    "  to the different tensors defined by the model.\n",
    "  \"\"\"\n",
    "  vggish_slim.define_vggish_slim()\n",
    "  checkpoint_path = 'vggish_model.ckpt'\n",
    "  vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
    "  \n",
    "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "\n",
    "  features_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.INPUT_TENSOR_NAME)\n",
    "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "  layers = {'conv1': 'vggish/conv1/Relu',\n",
    "            'pool1': 'vggish/pool1/MaxPool',\n",
    "            'conv2': 'vggish/conv2/Relu',\n",
    "            'pool2': 'vggish/pool2/MaxPool',\n",
    "            'conv3': 'vggish/conv3/conv3_2/Relu',\n",
    "            'pool3': 'vggish/pool3/MaxPool',\n",
    "            'conv4': 'vggish/conv4/conv4_2/Relu',\n",
    "            'pool4': 'vggish/pool4/MaxPool',\n",
    "            'fc1': 'vggish/fc1/fc1_2/Relu',\n",
    "            'fc2': 'vggish/fc2/Relu',\n",
    "            'embedding': 'vggish/embedding',\n",
    "            'features': 'vggish/input_features',\n",
    "         }\n",
    "  g = tf.get_default_graph()\n",
    "  for k in layers:\n",
    "    layers[k] = g.get_tensor_by_name( layers[k] + ':0')\n",
    "    \n",
    "  return {'features': features_tensor,\n",
    "          'embedding': embedding_tensor,\n",
    "          'layers': layers,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessWithVGGish(vgg, x, sr):\n",
    "  '''Run the VGGish model, starting with a sound (x) at sample rate\n",
    "  (sr). Return a whitened version of the embeddings. Sound must be scaled to be\n",
    "  floats between -1 and +1.'''\n",
    "\n",
    "  # Produce a batch of log mel spectrogram examples.\n",
    "  input_batch = vggish_input.waveform_to_examples(x, sr)\n",
    "  # print('Log Mel Spectrogram example: ', input_batch[0])\n",
    "\n",
    "  [embedding_batch] = sess.run([vgg['embedding']],\n",
    "                               feed_dict={vgg['features']: input_batch})\n",
    "  return embedding_batch\n",
    "  # Postprocess the results to produce whitened quantized embeddings.\n",
    "  pca_params_path = 'vggish_pca_params.npz'\n",
    "\n",
    "  pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
    "  postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "  # print('Postprocessed VGGish embedding: ', postprocessed_batch[0])\n",
    "  return postprocessed_batch[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "vgg = CreateVGGishNetwork(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sr, wav_data = wavfile.read(\"2.wav\")\n",
    "assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n",
    "samples = wav_data / 32768.0  # Convert to [-1.0, +1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14208000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ProcessWithVGGish(vgg,samples,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "values2 = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2[0]-values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 128)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import six\n",
    "num_secs = 5\n",
    "freq = 1000\n",
    "sr = 44100\n",
    "t = np.linspace(0, num_secs, int(num_secs * sr))\n",
    "x = np.sin(2 * np.pi * freq * t)\n",
    "# Convert to signed 16-bit samples.\n",
    "samples = np.clip(x * 32768, -32768, 32767).astype(np.int16)\n",
    "wav_file = six.BytesIO()\n",
    "wavfile.write(wav_file, sr, samples)\n",
    "wav_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-4.47771674 -4.29076017 -4.1532819  ... -3.98410919 -3.93030654\n",
      "   -3.76891238]\n",
      "  [-4.487119   -4.28663482 -4.14313869 ... -3.98851528 -3.9346542\n",
      "   -3.78824514]\n",
      "  [-4.460583   -4.29542372 -4.14568167 ... -3.97235414 -3.9172474\n",
      "   -3.79094514]\n",
      "  ...\n",
      "  [-4.45912554 -4.29392363 -4.14827892 ... -3.9534104  -3.94283579\n",
      "   -3.78986623]\n",
      "  [-4.45680333 -4.29347445 -4.15260834 ... -3.96181455 -3.92302184\n",
      "   -3.7812338 ]\n",
      "  [-4.46679676 -4.28966581 -4.15162289 ... -3.95698292 -3.94577437\n",
      "   -3.77947337]]\n",
      "\n",
      " [[-4.46342334 -4.29210809 -4.1494392  ... -3.96689471 -3.94103314\n",
      "   -3.78345147]\n",
      "  [-4.46518298 -4.29021104 -4.14963754 ... -3.9627394  -3.92718488\n",
      "   -3.78323181]\n",
      "  [-4.46232002 -4.29156065 -4.15015574 ... -3.96022267 -3.94609914\n",
      "   -3.79095732]\n",
      "  ...\n",
      "  [-4.47229232 -4.29333028 -4.15550377 ... -3.96550264 -3.92026994\n",
      "   -3.78052026]\n",
      "  [-4.47493192 -4.2918865  -4.15142573 ... -3.98084516 -3.93156007\n",
      "   -3.7891335 ]\n",
      "  [-4.47940576 -4.29223346 -4.14987884 ... -3.96548313 -3.91986638\n",
      "   -3.79126868]]\n",
      "\n",
      " [[-4.46926319 -4.29685915 -4.15156328 ... -3.96500609 -3.91222932\n",
      "   -3.7900678 ]\n",
      "  [-4.47276556 -4.29673794 -4.15075491 ... -3.96482089 -3.91794754\n",
      "   -3.79650331]\n",
      "  [-4.47487356 -4.29726996 -4.14731854 ... -3.96856033 -3.91985634\n",
      "   -3.77973007]\n",
      "  ...\n",
      "  [-4.47679705 -4.2961053  -4.15035518 ... -3.96795833 -3.91872255\n",
      "   -3.78407701]\n",
      "  [-4.47300326 -4.29837235 -4.14821442 ... -3.9702758  -3.92340342\n",
      "   -3.77752557]\n",
      "  [-4.47759835 -4.29756164 -4.14905149 ... -3.97453185 -3.92268533\n",
      "   -3.79832665]]\n",
      "\n",
      " [[-4.46767864 -4.30071457 -4.14822995 ... -3.97159526 -3.93586106\n",
      "   -3.78211682]\n",
      "  [-4.47294588 -4.29727751 -4.15148071 ... -3.97336393 -3.92533817\n",
      "   -3.78823568]\n",
      "  [-4.47622872 -4.29990245 -4.14548311 ... -3.97572014 -3.91896357\n",
      "   -3.78602715]\n",
      "  ...\n",
      "  [-4.47396608 -4.29576665 -4.15386776 ... -3.97650632 -3.92583995\n",
      "   -3.80448528]\n",
      "  [-4.47308408 -4.29919975 -4.14854364 ... -3.97616732 -3.93402544\n",
      "   -3.78303919]\n",
      "  [-4.47786302 -4.29644031 -4.15152332 ... -3.96268135 -3.91881913\n",
      "   -3.78750256]]\n",
      "\n",
      " [[-4.47880535 -4.29288046 -4.15260959 ... -3.97629037 -3.92548337\n",
      "   -3.79333322]\n",
      "  [-4.47313493 -4.29683448 -4.15347099 ... -3.97541802 -3.92078533\n",
      "   -3.80541728]\n",
      "  [-4.47403129 -4.29745159 -4.1496287  ... -3.97628983 -3.91284466\n",
      "   -3.79993816]\n",
      "  ...\n",
      "  [-4.47590011 -4.29562717 -4.15307856 ... -3.96048106 -3.91194497\n",
      "   -3.78103766]\n",
      "  [-4.47507773 -4.29569283 -4.15389675 ... -3.96935358 -3.91546103\n",
      "   -3.79467357]\n",
      "  [-4.47978364 -4.29499331 -4.15532353 ... -3.96896582 -3.9220332\n",
      "   -3.78633466]]]\n"
     ]
    }
   ],
   "source": [
    "examples_batch = vggish_input.wavfile_to_examples(wav_file)\n",
    "print(examples_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 96, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hop_length = int(round(\n",
    "        vggish_params.EXAMPLE_HOP_SECONDS * features_sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hop_length = int(round(\n",
    "        0.04 * features_sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_params.EXAMPLE_HOP_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gesture)",
   "language": "python",
   "name": "gesture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
